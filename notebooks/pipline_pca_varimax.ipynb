{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Configuration du chemin d'import pour modules personnalisés ===\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# === Bibliothèques standards ===\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# === Manipulation de données ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === Visualisation ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Machine Learning & Deep Learning ===\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from lime.lime_tabular import RecurrentTabularExplainer\n",
    "from scipy import optimize\n",
    "from tqdm import tqdm\n",
    "from factor_analyzer.rotator import Rotator\n",
    "\n",
    "# === Modules internes (utils + methods externe) ===\n",
    "from utils.model_function import *\n",
    "from utils.methods import *\n",
    "from utils.data_prep import *\n",
    "from utils.evaluator import *\n",
    "from utils.SHAP import *\n",
    "from utils.L2X import *\n",
    "\n",
    "# === Affichage inline (pour Jupyter Notebook uniquement) ===\n",
    "# %matplotlib inline  # Décommenter si vous êtes dans un notebook\n",
    "\n",
    "# === Suppression des avertissements ===\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === Fixation du seed pour la reproductibilité ===\n",
    "SEED = 0\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61249, 27) (41214, 26) (248, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Load data and preprocess\n",
    "train, test, y_test = prepare_data('FD004.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR', 'farB','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 120\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_1layer(input_shape, nodes_per_layer, dropout, activation):\n",
    "    \n",
    "    cb = keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = nodes_per_layer, activation=activation, \n",
    "                  input_shape=input_shape))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=0.001))\n",
    "    # model.save_weights(weights_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cr_train, X_cr_test= StandardScaler().fit_transform(X_train_interim[remaining_sensors]), StandardScaler().fit_transform(X_test_interim[remaining_sensors])\n",
    "# pca = PCA()\n",
    "\n",
    "# component_train , component_test = pca.fit(X_cr_train).transform(X_cr_train), pca.transform(X_cr_test)\n",
    "# # print(pca.explained_variance_, np_component) # choos component which lambda >1 # kaiser\n",
    "\n",
    "# np_component = len(pca.explained_variance_[pca.explained_variance_>1])\n",
    "# print(pca.explained_variance_,'\\n', \"Nb components: \", np_component) # choos component which lambda >1 # kaiser\n",
    "# comp = ['comp' + str(i) for i in range(1,np_component+1)]\n",
    "# X_train_interim[comp],  X_test_interim[comp]= component_train[:, :np_component], component_test[:, :np_component]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.95914066e+00 5.20347330e+00 1.05754225e+00 9.73443909e-01\n",
      " 6.01841369e-01 3.89076541e-01 1.95285565e-01 1.42521636e-01\n",
      " 1.18388892e-01 9.96185263e-02 9.54720058e-02 7.55025638e-02\n",
      " 3.73317439e-02 2.33308417e-02 1.38792003e-02 9.96708843e-03\n",
      " 4.46146340e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0 -3.804325  0.171658 -0.238337\n",
      "1 -5.588574  0.488095  0.626100\n",
      "2 -5.185448  0.229021  0.376971\n",
      "3 -4.784509 -0.302863  0.436564\n",
      "4 -4.834911 -0.288770  0.698135\n",
      "      comp1     comp2     comp3\n",
      "0 -7.033486 -0.269317  2.006290\n",
      "1 -5.642710 -1.017398  2.032851\n",
      "2 -5.716409 -1.393880  1.273379\n",
      "3 -5.905808 -1.307582  0.688476\n",
      "4 -5.688590 -1.080781  1.366046\n",
      "(51538, 40, 3) (51538, 1) (248, 40, 3)\n",
      "Epoch 1/20\n",
      "1611/1611 [==============================] - 22s 12ms/step - loss: 503.0244 - val_loss: 1402.4685\n",
      "Epoch 2/20\n",
      "1611/1611 [==============================] - 18s 11ms/step - loss: 269.2261 - val_loss: 1328.3180\n",
      "Epoch 3/20\n",
      "1611/1611 [==============================] - 19s 12ms/step - loss: 254.4655 - val_loss: 1285.3461\n",
      "Epoch 4/20\n",
      "1611/1611 [==============================] - 18s 11ms/step - loss: 242.5644 - val_loss: 1276.9049\n",
      "Epoch 5/20\n",
      "1611/1611 [==============================] - 18s 11ms/step - loss: 233.4155 - val_loss: 1228.7513\n",
      "Epoch 6/20\n",
      "1611/1611 [==============================] - 18s 11ms/step - loss: 223.2543 - val_loss: 1199.7305\n",
      "Epoch 7/20\n",
      "1611/1611 [==============================] - 34s 21ms/step - loss: 216.2625 - val_loss: 969.6927\n",
      "Epoch 8/20\n",
      "1611/1611 [==============================] - 33s 20ms/step - loss: 209.6166 - val_loss: 922.4934\n",
      "Epoch 9/20\n",
      "1611/1611 [==============================] - 32s 20ms/step - loss: 202.4806 - val_loss: 868.2001\n",
      "Epoch 10/20\n",
      "1611/1611 [==============================] - 34s 21ms/step - loss: 198.8563 - val_loss: 803.3528\n",
      "Epoch 11/20\n",
      "1611/1611 [==============================] - 35s 22ms/step - loss: 193.6340 - val_loss: 692.6352\n",
      "Epoch 12/20\n",
      "1611/1611 [==============================] - 35s 21ms/step - loss: 189.1923 - val_loss: 705.6129\n",
      "Epoch 13/20\n",
      "1611/1611 [==============================] - 35s 22ms/step - loss: 182.6710 - val_loss: 704.4163\n",
      "Epoch 14/20\n",
      "1611/1611 [==============================] - 34s 21ms/step - loss: 178.4747 - val_loss: 765.2903\n",
      "Epoch 15/20\n",
      "1611/1611 [==============================] - 33s 21ms/step - loss: 174.2327 - val_loss: 758.6478\n",
      "8/8 [==============================] - 1s 10ms/step\n",
      "[7.95914066e+00 5.20347330e+00 1.05754225e+00 9.73443909e-01\n",
      " 6.01841369e-01 3.89076541e-01 1.95285565e-01 1.42521636e-01\n",
      " 1.18388892e-01 9.96185263e-02 9.54720058e-02 7.55025638e-02\n",
      " 3.73317439e-02 2.33308417e-02 1.38792003e-02 9.96708843e-03\n",
      " 4.46146340e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0 -3.804325  0.171658 -0.238337\n",
      "1 -5.588574  0.488095  0.626100\n",
      "2 -5.185448  0.229021  0.376971\n",
      "3 -4.784509 -0.302863  0.436564\n",
      "4 -4.834911 -0.288770  0.698135\n",
      "      comp1     comp2     comp3\n",
      "0 -7.033486 -0.269317  2.006290\n",
      "1 -5.642710 -1.017398  2.032851\n",
      "2 -5.716409 -1.393880  1.273379\n",
      "3 -5.905808 -1.307582  0.688476\n",
      "4 -5.688590 -1.080781  1.366046\n",
      "(51538, 40, 3) (51538, 1) (248, 40, 3)\n",
      "Epoch 1/20\n",
      "1611/1611 [==============================] - 38s 21ms/step - loss: 528.0475 - val_loss: 1122.6222\n",
      "Epoch 2/20\n",
      "1611/1611 [==============================] - 32s 20ms/step - loss: 269.7748 - val_loss: 1234.2692\n",
      "Epoch 3/20\n",
      "1611/1611 [==============================] - 32s 20ms/step - loss: 258.0497 - val_loss: 1523.1365\n",
      "Epoch 4/20\n",
      "1611/1611 [==============================] - 33s 20ms/step - loss: 247.6119 - val_loss: 1532.6929\n",
      "Epoch 5/20\n",
      "1611/1611 [==============================] - 33s 20ms/step - loss: 237.3394 - val_loss: 1522.6572\n",
      "8/8 [==============================] - 1s 9ms/step\n",
      "[7.95914066e+00 5.20347330e+00 1.05754225e+00 9.73443909e-01\n",
      " 6.01841369e-01 3.89076541e-01 1.95285565e-01 1.42521636e-01\n",
      " 1.18388892e-01 9.96185263e-02 9.54720058e-02 7.55025638e-02\n",
      " 3.73317439e-02 2.33308417e-02 1.38792003e-02 9.96708843e-03\n",
      " 4.46146340e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0 -3.804325  0.171658 -0.238337\n",
      "1 -5.588574  0.488095  0.626100\n",
      "2 -5.185448  0.229021  0.376971\n",
      "3 -4.784509 -0.302863  0.436564\n",
      "4 -4.834911 -0.288770  0.698135\n",
      "      comp1     comp2     comp3\n",
      "0 -7.033486 -0.269317  2.006290\n",
      "1 -5.642710 -1.017398  2.032851\n",
      "2 -5.716409 -1.393880  1.273379\n",
      "3 -5.905808 -1.307582  0.688476\n",
      "4 -5.688590 -1.080781  1.366046\n",
      "(51538, 40, 3) (51538, 1) (248, 40, 3)\n",
      "Epoch 1/20\n",
      "1611/1611 [==============================] - 39s 22ms/step - loss: 536.8066 - val_loss: 1212.8257\n",
      "Epoch 2/20\n",
      "1611/1611 [==============================] - 35s 22ms/step - loss: 285.4828 - val_loss: 1192.5206\n",
      "Epoch 3/20\n",
      "1611/1611 [==============================] - 34s 21ms/step - loss: 258.9712 - val_loss: 1283.2390\n",
      "Epoch 4/20\n",
      "1611/1611 [==============================] - 34s 21ms/step - loss: 248.7533 - val_loss: 1336.0381\n",
      "Epoch 5/20\n",
      "1611/1611 [==============================] - 27s 17ms/step - loss: 236.8544 - val_loss: 1304.7360\n",
      "Epoch 6/20\n",
      "1611/1611 [==============================] - 20s 13ms/step - loss: 231.3139 - val_loss: 1242.6619\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "[7.95914066e+00 5.20347330e+00 1.05754225e+00 9.73443909e-01\n",
      " 6.01841369e-01 3.89076541e-01 1.95285565e-01 1.42521636e-01\n",
      " 1.18388892e-01 9.96185263e-02 9.54720058e-02 7.55025638e-02\n",
      " 3.73317439e-02 2.33308417e-02 1.38792003e-02 9.96708843e-03\n",
      " 4.46146340e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0 -3.804325  0.171658 -0.238337\n",
      "1 -5.588574  0.488095  0.626100\n",
      "2 -5.185448  0.229021  0.376971\n",
      "3 -4.784509 -0.302863  0.436564\n",
      "4 -4.834911 -0.288770  0.698135\n",
      "      comp1     comp2     comp3\n",
      "0 -7.033486 -0.269317  2.006290\n",
      "1 -5.642710 -1.017398  2.032851\n",
      "2 -5.716409 -1.393880  1.273379\n",
      "3 -5.905808 -1.307582  0.688476\n",
      "4 -5.688590 -1.080781  1.366046\n",
      "(51538, 40, 3) (51538, 1) (248, 40, 3)\n",
      "Epoch 1/20\n",
      "1611/1611 [==============================] - 25s 14ms/step - loss: 518.5597 - val_loss: 1245.1437\n",
      "Epoch 2/20\n",
      "1611/1611 [==============================] - 20s 13ms/step - loss: 276.0224 - val_loss: 1190.4917\n",
      "Epoch 3/20\n",
      "1611/1611 [==============================] - 21s 13ms/step - loss: 257.2913 - val_loss: 993.6420\n",
      "Epoch 4/20\n",
      "1611/1611 [==============================] - 28s 17ms/step - loss: 245.4345 - val_loss: 1003.5090\n",
      "Epoch 5/20\n",
      "1611/1611 [==============================] - 35s 22ms/step - loss: 236.9561 - val_loss: 929.1722\n",
      "Epoch 6/20\n",
      "1611/1611 [==============================] - 35s 21ms/step - loss: 227.6416 - val_loss: 1071.3539\n",
      "Epoch 7/20\n",
      "1611/1611 [==============================] - 10s 6ms/step - loss: 221.4136 - val_loss: 983.6478\n",
      "Epoch 8/20\n",
      "1611/1611 [==============================] - 10s 6ms/step - loss: 214.6034 - val_loss: 998.0571\n",
      "Epoch 9/20\n",
      "1611/1611 [==============================] - 9s 6ms/step - loss: 208.7347 - val_loss: 904.6982\n",
      "Epoch 10/20\n",
      "1611/1611 [==============================] - 10s 7ms/step - loss: 203.8447 - val_loss: 868.4832\n",
      "Epoch 11/20\n",
      "1611/1611 [==============================] - 11s 7ms/step - loss: 200.5613 - val_loss: 931.1753\n",
      "Epoch 12/20\n",
      "1611/1611 [==============================] - 12s 7ms/step - loss: 194.1383 - val_loss: 976.5948\n",
      "Epoch 13/20\n",
      "1611/1611 [==============================] - 11s 7ms/step - loss: 189.0522 - val_loss: 866.5089\n",
      "Epoch 14/20\n",
      "1611/1611 [==============================] - 11s 7ms/step - loss: 182.9176 - val_loss: 839.1244\n",
      "Epoch 15/20\n",
      "1611/1611 [==============================] - 12s 7ms/step - loss: 175.0516 - val_loss: 880.2097\n",
      "Epoch 16/20\n",
      "1611/1611 [==============================] - 15s 9ms/step - loss: 168.6026 - val_loss: 820.6225\n",
      "Epoch 17/20\n",
      "1611/1611 [==============================] - 13s 8ms/step - loss: 164.5223 - val_loss: 859.0265\n",
      "Epoch 18/20\n",
      "1611/1611 [==============================] - 14s 9ms/step - loss: 157.5280 - val_loss: 793.0650\n",
      "Epoch 19/20\n",
      "1611/1611 [==============================] - 17s 10ms/step - loss: 153.5011 - val_loss: 877.3195\n",
      "Epoch 20/20\n",
      "1611/1611 [==============================] - 17s 11ms/step - loss: 147.2941 - val_loss: 865.8858\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "[7.95914066e+00 5.20347330e+00 1.05754225e+00 9.73443909e-01\n",
      " 6.01841369e-01 3.89076541e-01 1.95285565e-01 1.42521636e-01\n",
      " 1.18388892e-01 9.96185263e-02 9.54720058e-02 7.55025638e-02\n",
      " 3.73317439e-02 2.33308417e-02 1.38792003e-02 9.96708843e-03\n",
      " 4.46146340e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0 -3.804325  0.171658 -0.238337\n",
      "1 -5.588574  0.488095  0.626100\n",
      "2 -5.185448  0.229021  0.376971\n",
      "3 -4.784509 -0.302863  0.436564\n",
      "4 -4.834911 -0.288770  0.698135\n",
      "      comp1     comp2     comp3\n",
      "0 -7.033486 -0.269317  2.006290\n",
      "1 -5.642710 -1.017398  2.032851\n",
      "2 -5.716409 -1.393880  1.273379\n",
      "3 -5.905808 -1.307582  0.688476\n",
      "4 -5.688590 -1.080781  1.366046\n",
      "(51538, 40, 3) (51538, 1) (248, 40, 3)\n",
      "Epoch 1/20\n",
      "1611/1611 [==============================] - 21s 12ms/step - loss: 508.3182 - val_loss: 2144.7195\n",
      "Epoch 2/20\n",
      "1611/1611 [==============================] - 16s 10ms/step - loss: 273.8953 - val_loss: 1606.8706\n",
      "Epoch 3/20\n",
      "1611/1611 [==============================] - 16s 10ms/step - loss: 259.2194 - val_loss: 1333.9327\n",
      "Epoch 4/20\n",
      "1611/1611 [==============================] - 19s 12ms/step - loss: 246.0231 - val_loss: 1285.2214\n",
      "Epoch 5/20\n",
      "1611/1611 [==============================] - 17s 11ms/step - loss: 237.5567 - val_loss: 1102.6492\n",
      "Epoch 6/20\n",
      "1611/1611 [==============================] - 17s 10ms/step - loss: 227.9084 - val_loss: 1023.5364\n",
      "Epoch 7/20\n",
      "1611/1611 [==============================] - 18s 11ms/step - loss: 219.8513 - val_loss: 1191.6471\n",
      "Epoch 8/20\n",
      "1611/1611 [==============================] - 20s 13ms/step - loss: 214.4514 - val_loss: 953.5544\n",
      "Epoch 9/20\n",
      "1611/1611 [==============================] - 19s 12ms/step - loss: 209.0342 - val_loss: 964.9187\n",
      "Epoch 10/20\n",
      "1611/1611 [==============================] - 19s 12ms/step - loss: 203.3370 - val_loss: 967.9586\n",
      "Epoch 11/20\n",
      "1611/1611 [==============================] - 19s 12ms/step - loss: 197.6634 - val_loss: 827.9048\n",
      "Epoch 12/20\n",
      "1611/1611 [==============================] - 20s 12ms/step - loss: 190.3252 - val_loss: 825.9439\n",
      "Epoch 13/20\n",
      "1611/1611 [==============================] - 20s 12ms/step - loss: 185.3834 - val_loss: 1013.3745\n",
      "Epoch 14/20\n",
      "1611/1611 [==============================] - 16s 10ms/step - loss: 179.4693 - val_loss: 855.4536\n",
      "Epoch 15/20\n",
      "1611/1611 [==============================] - 16s 10ms/step - loss: 172.8497 - val_loss: 950.4931\n",
      "Epoch 16/20\n",
      "1611/1611 [==============================] - 17s 10ms/step - loss: 169.3006 - val_loss: 1042.3370\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "CPU times: total: 1h 12min 7s\n",
      "Wall time: 23min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_pca = pd.DataFrame()\n",
    "for SEED in range(5):  \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    # 0.20\t[64]\t0.3\ttanh\t32\t25\n",
    "    \n",
    "    # parameter's sample\n",
    "    # weights_file = \"weights_file_lstm_optimalmodel_all.h5\"\n",
    "    alpha = 0.3\n",
    "    sequence_length = 40\n",
    "    epochs = 20\n",
    "    nodes_per_layer = [64]\n",
    "    dropout = 0.2\n",
    "    activation = 'tanh'\n",
    "    batch_size = 32\n",
    "    remaining_sensors = remaining_sensors\n",
    "    # create model\n",
    "    # input_shape = (sequence_length, len(remaining_sensors))\n",
    "    # model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "    \n",
    "    #PCA data reduction \n",
    "    X_cr_train, X_cr_test= StandardScaler().fit_transform(X_train_interim[remaining_sensors]), StandardScaler().fit_transform(X_test_interim[remaining_sensors])\n",
    "    pca = PCA()\n",
    "    component_train , component_test = pca.fit(X_cr_train).transform(X_cr_train), pca.transform(X_cr_test)\n",
    "    # print(pca.explained_variance_, np_component) # choos component which lambda >1 # kaiser\n",
    "\n",
    "    np_component = len(pca.explained_variance_[pca.explained_variance_>1])\n",
    "    # np_component = 4\n",
    "    print(pca.explained_variance_,'\\n', \"Nb components: \", np_component) # choos component which lambda >1 # kaiser\n",
    "    comp = ['comp' + str(i) for i in range(1,np_component+1)]\n",
    "    X_train_interim[comp],  X_test_interim[comp]= component_train[:, :np_component], component_test[:, :np_component]\n",
    "    \n",
    "    #rotation \n",
    "    rotator = Rotator(method='varimax')\n",
    "    X_train_interim[comp] = rotator.fit_transform(X_train_interim[comp])\n",
    "    X_test_interim[comp] = rotator.fit_transform(X_test_interim[comp])\n",
    "    print(X_train_interim[comp].head())\n",
    "    print(X_test_interim[comp].head())\n",
    "    # print(X_train_interim[comp].shape, X_test_interim[comp].shape)\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length, comp)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length, comp, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    \n",
    "    input_shape = (sequence_length, len(comp))\n",
    "    model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "            \n",
    "    # Model fitting\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        start_time = time.time()\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        weights_file = model.get_weights()\n",
    "        model.set_weights(weights_file)  # reset optimizer and node weights before every training iteration\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size, 'TW' : sequence_length,\n",
    "         'time': training_time}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results_pca = pd.concat([results_pca, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    results_pca.to_csv('../results/pca/fd004_varimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>TW</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.317962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6822.032115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>758.647827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>416.924613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.505556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15303.876841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1522.657227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>168.295775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.532893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19392.498365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242.661865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>189.506618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.425937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7581.310541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>865.885803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>336.332053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.739241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7751.887639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1042.337036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>287.685031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  std_RMSE       S_score  std_S_score          MSE  std_MSE nodes  \\\n",
       "0  26.317962       0.0   6822.032115          0.0   758.647827      0.0  [64]   \n",
       "1  33.505556       0.0  15303.876841          0.0  1522.657227      0.0  [64]   \n",
       "2  34.532893       0.0  19392.498365          0.0  1242.661865      0.0  [64]   \n",
       "3  29.425937       0.0   7581.310541          0.0   865.885803      0.0  [64]   \n",
       "4  28.739241       0.0   7751.887639          0.0  1042.337036      0.0  [64]   \n",
       "\n",
       "   dropout activation  batch_size  TW        time  \n",
       "0      0.2       tanh          32  40  416.924613  \n",
       "1      0.2       tanh          32  40  168.295775  \n",
       "2      0.2       tanh          32  40  189.506618  \n",
       "3      0.2       tanh          32  40  336.332053  \n",
       "4      0.2       tanh          32  40  287.685031  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53759, 27) (33991, 26) (259, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Load data and preprocess\n",
    "train, test, y_test = prepare_data('FD002.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 125\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04271508e+01 2.66149542e+00 1.05555422e+00 4.67459514e-01\n",
      " 2.81050559e-01 2.11386654e-01 1.92544371e-01 1.64287263e-01\n",
      " 1.32272442e-01 1.16578816e-01 1.04679947e-01 7.46965656e-02\n",
      " 4.85539287e-02 3.45854321e-02 1.97697647e-02 8.23190831e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0  0.237497 -4.288898 -1.123881\n",
      "1  0.866028 -3.819474 -1.219568\n",
      "2  0.635171 -3.323800  0.780730\n",
      "3 -0.275638 -3.436208 -0.208620\n",
      "4  0.473778 -3.251752  0.864355\n",
      "      comp1     comp2     comp3\n",
      "0 -0.010903  0.632199  3.488154\n",
      "1 -1.137766 -1.016830  2.856822\n",
      "2 -1.142163 -2.675207  1.094389\n",
      "3 -0.000756 -3.208743  0.308315\n",
      "4 -0.741858 -3.012953  1.068638\n",
      "(43619, 40, 3) (43619, 1) (259, 40, 3)\n",
      "Epoch 1/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 1377.6382 - val_loss: 910.2474\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 411.2484 - val_loss: 850.5428\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 366.5379 - val_loss: 783.7528\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 8s 25ms/step - loss: 335.6092 - val_loss: 814.3849\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 7s 22ms/step - loss: 290.8124 - val_loss: 935.2240\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 282.0913 - val_loss: 907.6777\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 267.1186 - val_loss: 924.1570\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "[1.04271508e+01 2.66149542e+00 1.05555422e+00 4.67459514e-01\n",
      " 2.81050559e-01 2.11386654e-01 1.92544371e-01 1.64287263e-01\n",
      " 1.32272442e-01 1.16578816e-01 1.04679947e-01 7.46965656e-02\n",
      " 4.85539287e-02 3.45854321e-02 1.97697647e-02 8.23190831e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0  0.237497 -4.288898 -1.123881\n",
      "1  0.866028 -3.819474 -1.219568\n",
      "2  0.635171 -3.323800  0.780730\n",
      "3 -0.275638 -3.436208 -0.208620\n",
      "4  0.473778 -3.251752  0.864355\n",
      "      comp1     comp2     comp3\n",
      "0 -0.010903  0.632199  3.488154\n",
      "1 -1.137766 -1.016830  2.856822\n",
      "2 -1.142163 -2.675207  1.094389\n",
      "3 -0.000756 -3.208743  0.308315\n",
      "4 -0.741858 -3.012953  1.068638\n",
      "(43619, 40, 3) (43619, 1) (259, 40, 3)\n",
      "Epoch 1/20\n",
      "341/341 [==============================] - 6s 15ms/step - loss: 1393.0367 - val_loss: 848.0673\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 273.3388 - val_loss: 700.5092\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 253.2664 - val_loss: 765.7514\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 248.2906 - val_loss: 786.2305\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 243.8220 - val_loss: 787.8735\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 238.7733 - val_loss: 739.9448\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "[1.04271508e+01 2.66149542e+00 1.05555422e+00 4.67459514e-01\n",
      " 2.81050559e-01 2.11386654e-01 1.92544371e-01 1.64287263e-01\n",
      " 1.32272442e-01 1.16578816e-01 1.04679947e-01 7.46965656e-02\n",
      " 4.85539287e-02 3.45854321e-02 1.97697647e-02 8.23190831e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0  0.237497 -4.288898 -1.123881\n",
      "1  0.866028 -3.819474 -1.219568\n",
      "2  0.635171 -3.323800  0.780730\n",
      "3 -0.275638 -3.436208 -0.208620\n",
      "4  0.473778 -3.251752  0.864355\n",
      "      comp1     comp2     comp3\n",
      "0 -0.010903  0.632199  3.488154\n",
      "1 -1.137766 -1.016830  2.856822\n",
      "2 -1.142163 -2.675207  1.094389\n",
      "3 -0.000756 -3.208743  0.308315\n",
      "4 -0.741858 -3.012953  1.068638\n",
      "(43619, 40, 3) (43619, 1) (259, 40, 3)\n",
      "Epoch 1/20\n",
      "341/341 [==============================] - 6s 13ms/step - loss: 1350.8615 - val_loss: 887.1956\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 272.6590 - val_loss: 766.4417\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 252.4792 - val_loss: 711.0568\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 247.5492 - val_loss: 745.3109\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 242.6626 - val_loss: 720.2001\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 239.7834 - val_loss: 785.7823\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 239.2557 - val_loss: 756.6974\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "[1.04271508e+01 2.66149542e+00 1.05555422e+00 4.67459514e-01\n",
      " 2.81050559e-01 2.11386654e-01 1.92544371e-01 1.64287263e-01\n",
      " 1.32272442e-01 1.16578816e-01 1.04679947e-01 7.46965656e-02\n",
      " 4.85539287e-02 3.45854321e-02 1.97697647e-02 8.23190831e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0  0.237497 -4.288898 -1.123881\n",
      "1  0.866028 -3.819474 -1.219568\n",
      "2  0.635171 -3.323800  0.780730\n",
      "3 -0.275638 -3.436208 -0.208620\n",
      "4  0.473778 -3.251752  0.864355\n",
      "      comp1     comp2     comp3\n",
      "0 -0.010903  0.632199  3.488154\n",
      "1 -1.137766 -1.016830  2.856822\n",
      "2 -1.142163 -2.675207  1.094389\n",
      "3 -0.000756 -3.208743  0.308315\n",
      "4 -0.741858 -3.012953  1.068638\n",
      "(43619, 40, 3) (43619, 1) (259, 40, 3)\n",
      "Epoch 1/20\n",
      "341/341 [==============================] - 5s 12ms/step - loss: 1395.2600 - val_loss: 873.2625\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 435.6187 - val_loss: 894.5566\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 395.2941 - val_loss: 907.8814\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 302.1502 - val_loss: 746.7065\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 255.2993 - val_loss: 774.3070\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 245.7578 - val_loss: 693.2014\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 239.6325 - val_loss: 758.3086\n",
      "Epoch 8/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 238.2076 - val_loss: 684.4951\n",
      "Epoch 9/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 235.0944 - val_loss: 688.1859\n",
      "Epoch 10/20\n",
      "341/341 [==============================] - 6s 16ms/step - loss: 231.6016 - val_loss: 710.0032\n",
      "Epoch 11/20\n",
      "341/341 [==============================] - 9s 25ms/step - loss: 231.2249 - val_loss: 715.2165\n",
      "Epoch 12/20\n",
      "341/341 [==============================] - 8s 23ms/step - loss: 229.4048 - val_loss: 707.4111\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "[1.04271508e+01 2.66149542e+00 1.05555422e+00 4.67459514e-01\n",
      " 2.81050559e-01 2.11386654e-01 1.92544371e-01 1.64287263e-01\n",
      " 1.32272442e-01 1.16578816e-01 1.04679947e-01 7.46965656e-02\n",
      " 4.85539287e-02 3.45854321e-02 1.97697647e-02 8.23190831e-03] \n",
      " Nb components:  3\n",
      "      comp1     comp2     comp3\n",
      "0  0.237497 -4.288898 -1.123881\n",
      "1  0.866028 -3.819474 -1.219568\n",
      "2  0.635171 -3.323800  0.780730\n",
      "3 -0.275638 -3.436208 -0.208620\n",
      "4  0.473778 -3.251752  0.864355\n",
      "      comp1     comp2     comp3\n",
      "0 -0.010903  0.632199  3.488154\n",
      "1 -1.137766 -1.016830  2.856822\n",
      "2 -1.142163 -2.675207  1.094389\n",
      "3 -0.000756 -3.208743  0.308315\n",
      "4 -0.741858 -3.012953  1.068638\n",
      "(43619, 40, 3) (43619, 1) (259, 40, 3)\n",
      "Epoch 1/20\n",
      "341/341 [==============================] - 7s 16ms/step - loss: 1443.4392 - val_loss: 839.5276\n",
      "Epoch 2/20\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 402.9193 - val_loss: 957.4196\n",
      "Epoch 3/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 268.6957 - val_loss: 848.7545\n",
      "Epoch 4/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 251.5473 - val_loss: 747.3755\n",
      "Epoch 5/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 245.4779 - val_loss: 745.1477\n",
      "Epoch 6/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 243.0750 - val_loss: 761.9427\n",
      "Epoch 7/20\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 238.9118 - val_loss: 766.1013\n",
      "Epoch 8/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 238.4345 - val_loss: 732.3933\n",
      "Epoch 9/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 235.9006 - val_loss: 729.3781\n",
      "Epoch 10/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 233.5885 - val_loss: 757.4957\n",
      "Epoch 11/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 233.3951 - val_loss: 699.7310\n",
      "Epoch 12/20\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 229.2651 - val_loss: 700.3246\n",
      "Epoch 13/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 228.0436 - val_loss: 764.3718\n",
      "Epoch 14/20\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 226.8268 - val_loss: 688.2844\n",
      "Epoch 15/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 225.4683 - val_loss: 719.1265\n",
      "Epoch 16/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 223.2034 - val_loss: 748.6246\n",
      "Epoch 17/20\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 220.5911 - val_loss: 712.1164\n",
      "Epoch 18/20\n",
      "341/341 [==============================] - 5s 16ms/step - loss: 220.0474 - val_loss: 677.2020\n",
      "Epoch 19/20\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 219.6207 - val_loss: 688.4320\n",
      "Epoch 20/20\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 217.0917 - val_loss: 693.2380\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "CPU times: total: 11min 51s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_pca002 = pd.DataFrame()\n",
    "for SEED in range(5):  \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    # 0.20\t[64]\t0.3\ttanh\t32\t25\n",
    "    \n",
    "    # parameter's sample\n",
    "    # weights_file = \"weights_file_lstm_optimalmodel_all.h5\"\n",
    "    alpha = 0.2\n",
    "    sequence_length = 40\n",
    "    epochs = 20\n",
    "    nodes_per_layer = [32]\n",
    "    dropout = 0.1\n",
    "    activation = 'tanh'\n",
    "    batch_size = 128\n",
    "    remaining_sensors = remaining_sensors\n",
    "    # create model\n",
    "    input_shape = (sequence_length, len(remaining_sensors))\n",
    "    model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "    \n",
    "    #PCA data reduction \n",
    "    X_cr_train, X_cr_test= StandardScaler().fit_transform(X_train_interim[remaining_sensors]), StandardScaler().fit_transform(X_test_interim[remaining_sensors])\n",
    "    pca = PCA()\n",
    "    component_train , component_test = pca.fit(X_cr_train).transform(X_cr_train), pca.transform(X_cr_test)\n",
    "    # print(pca.explained_variance_, np_component) # choos component which lambda >1 # kaiser\n",
    "\n",
    "    np_component = len(pca.explained_variance_[pca.explained_variance_>1])\n",
    "    print(pca.explained_variance_,'\\n', \"Nb components: \", np_component) # choos component which lambda >1 # kaiser\n",
    "    comp = ['comp' + str(i) for i in range(1,np_component+1)]\n",
    "    X_train_interim[comp],  X_test_interim[comp]= component_train[:, :np_component], component_test[:, :np_component]\n",
    "    \n",
    "    # Rotate\n",
    "    rotator = Rotator(method='varimax')\n",
    "    X_train_interim[comp] = rotator.fit_transform(X_train_interim[comp])\n",
    "    X_test_interim[comp] = rotator.fit_transform(X_test_interim[comp])\n",
    "    print(X_train_interim[comp].head())\n",
    "    print(X_test_interim[comp].head())\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length, comp)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,comp, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    \n",
    "    input_shape = (sequence_length, len(comp))\n",
    "    model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "            \n",
    "    # Model fitting\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        start_time = time.time()\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        weights_file = model.get_weights()\n",
    "        model.set_weights(weights_file)  # reset optimizer and node weights before every training iteration\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size, 'TW' : sequence_length,\n",
    "         'time': training_time}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results_pca002 = pd.concat([results_pca002, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    results_pca002.to_csv('../results/pca/fd002_varimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>TW</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.995586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4261.021336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>924.156982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>40.749763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.467134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3526.288108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>739.944763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>28.815168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.665649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3993.771572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>756.697449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>31.342091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.162858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3398.607448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>707.411072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>61.218324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.329413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4707.650054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.237976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[32]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>92.156073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  std_RMSE      S_score  std_S_score         MSE  std_MSE nodes  \\\n",
       "0  27.995586       0.0  4261.021336          0.0  924.156982      0.0  [32]   \n",
       "1  26.467134       0.0  3526.288108          0.0  739.944763      0.0  [32]   \n",
       "2  26.665649       0.0  3993.771572          0.0  756.697449      0.0  [32]   \n",
       "3  26.162858       0.0  3398.607448          0.0  707.411072      0.0  [32]   \n",
       "4  26.329413       0.0  4707.650054          0.0  693.237976      0.0  [32]   \n",
       "\n",
       "   dropout activation  batch_size  TW       time  \n",
       "0      0.1       tanh         128  40  40.749763  \n",
       "1      0.1       tanh         128  40  28.815168  \n",
       "2      0.1       tanh         128  40  31.342091  \n",
       "3      0.1       tanh         128  40  61.218324  \n",
       "4      0.1       tanh         128  40  92.156073  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pca002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24720, 27) (16596, 26) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Load data and preprocess\n",
    "train, test, y_test = prepare_data('FD003.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc', 'epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 125\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.19095667e+00 5.49399656e+00 8.81347307e-01 7.81564822e-01\n",
      " 3.51238057e-01 1.43235420e-01 4.09913921e-02 3.53324081e-02\n",
      " 2.44339253e-02 1.75337353e-02 1.33853528e-02 1.23424994e-02\n",
      " 6.63828566e-03 3.52672765e-03 3.10180225e-03 1.02230366e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -1.538312 -0.544704\n",
      "1 -0.930198 -0.333238\n",
      "2 -0.870208 -0.240347\n",
      "3 -0.788517 -0.178757\n",
      "4 -0.909442 -0.304579\n",
      "      comp1     comp2\n",
      "0 -0.623506 -2.289400\n",
      "1 -0.450795 -1.901779\n",
      "2 -0.334288 -2.275177\n",
      "3 -0.622983 -1.845581\n",
      "4 -0.643156 -1.711918\n",
      "(21320, 35, 2) (21320, 1) (100, 35, 2)\n",
      "Epoch 1/20\n",
      "667/667 [==============================] - 9s 12ms/step - loss: 841.1613 - val_loss: 971.8094\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 270.1686 - val_loss: 792.8654\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 8s 11ms/step - loss: 206.3273 - val_loss: 781.8575\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 189.6050 - val_loss: 920.0706\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 6s 10ms/step - loss: 182.4837 - val_loss: 836.2640\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 180.0625 - val_loss: 1100.1715\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 173.8051 - val_loss: 1117.5778\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "[8.19095667e+00 5.49399656e+00 8.81347307e-01 7.81564822e-01\n",
      " 3.51238057e-01 1.43235420e-01 4.09913921e-02 3.53324081e-02\n",
      " 2.44339253e-02 1.75337353e-02 1.33853528e-02 1.23424994e-02\n",
      " 6.63828566e-03 3.52672765e-03 3.10180225e-03 1.02230366e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -1.538312 -0.544704\n",
      "1 -0.930198 -0.333238\n",
      "2 -0.870208 -0.240347\n",
      "3 -0.788517 -0.178757\n",
      "4 -0.909442 -0.304579\n",
      "      comp1     comp2\n",
      "0 -0.623506 -2.289400\n",
      "1 -0.450795 -1.901779\n",
      "2 -0.334288 -2.275177\n",
      "3 -0.622983 -1.845581\n",
      "4 -0.643156 -1.711918\n",
      "(21320, 35, 2) (21320, 1) (100, 35, 2)\n",
      "Epoch 1/20\n",
      "667/667 [==============================] - 10s 13ms/step - loss: 891.5741 - val_loss: 1215.9171\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 286.9450 - val_loss: 759.2653\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 214.3802 - val_loss: 875.7687\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 197.1629 - val_loss: 780.0215\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 9s 13ms/step - loss: 187.4969 - val_loss: 707.8561\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 181.5392 - val_loss: 674.3245\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 175.3326 - val_loss: 588.5540\n",
      "Epoch 8/20\n",
      "667/667 [==============================] - 6s 10ms/step - loss: 166.8518 - val_loss: 805.7766\n",
      "Epoch 9/20\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 165.7771 - val_loss: 617.9232\n",
      "Epoch 10/20\n",
      "667/667 [==============================] - 8s 13ms/step - loss: 160.8381 - val_loss: 725.2991\n",
      "Epoch 11/20\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 155.8568 - val_loss: 791.4077\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "[8.19095667e+00 5.49399656e+00 8.81347307e-01 7.81564822e-01\n",
      " 3.51238057e-01 1.43235420e-01 4.09913921e-02 3.53324081e-02\n",
      " 2.44339253e-02 1.75337353e-02 1.33853528e-02 1.23424994e-02\n",
      " 6.63828566e-03 3.52672765e-03 3.10180225e-03 1.02230366e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -1.538312 -0.544704\n",
      "1 -0.930198 -0.333238\n",
      "2 -0.870208 -0.240347\n",
      "3 -0.788517 -0.178757\n",
      "4 -0.909442 -0.304579\n",
      "      comp1     comp2\n",
      "0 -0.623506 -2.289400\n",
      "1 -0.450795 -1.901779\n",
      "2 -0.334288 -2.275177\n",
      "3 -0.622983 -1.845581\n",
      "4 -0.643156 -1.711918\n",
      "(21320, 35, 2) (21320, 1) (100, 35, 2)\n",
      "Epoch 1/20\n",
      "667/667 [==============================] - 11s 13ms/step - loss: 865.6614 - val_loss: 1005.4155\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 345.6014 - val_loss: 1055.8489\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 9s 14ms/step - loss: 254.7627 - val_loss: 648.9625\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 8s 12ms/step - loss: 203.4593 - val_loss: 620.8395\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 187.7482 - val_loss: 690.4439\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 180.0979 - val_loss: 715.4385\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 171.8441 - val_loss: 675.3646\n",
      "Epoch 8/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 170.7987 - val_loss: 701.4318\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "[8.19095667e+00 5.49399656e+00 8.81347307e-01 7.81564822e-01\n",
      " 3.51238057e-01 1.43235420e-01 4.09913921e-02 3.53324081e-02\n",
      " 2.44339253e-02 1.75337353e-02 1.33853528e-02 1.23424994e-02\n",
      " 6.63828566e-03 3.52672765e-03 3.10180225e-03 1.02230366e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -1.538312 -0.544704\n",
      "1 -0.930198 -0.333238\n",
      "2 -0.870208 -0.240347\n",
      "3 -0.788517 -0.178757\n",
      "4 -0.909442 -0.304579\n",
      "      comp1     comp2\n",
      "0 -0.623506 -2.289400\n",
      "1 -0.450795 -1.901779\n",
      "2 -0.334288 -2.275177\n",
      "3 -0.622983 -1.845581\n",
      "4 -0.643156 -1.711918\n",
      "(21320, 35, 2) (21320, 1) (100, 35, 2)\n",
      "Epoch 1/20\n",
      "667/667 [==============================] - 8s 10ms/step - loss: 855.0592 - val_loss: 1122.7408\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 355.3474 - val_loss: 966.1761\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 299.0764 - val_loss: 721.4997\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 213.3748 - val_loss: 758.3223\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 187.5732 - val_loss: 705.3993\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 6s 10ms/step - loss: 183.2723 - val_loss: 725.3500\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 178.3592 - val_loss: 647.0382\n",
      "Epoch 8/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 168.8219 - val_loss: 500.8842\n",
      "Epoch 9/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 168.9702 - val_loss: 635.1050\n",
      "Epoch 10/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 163.3074 - val_loss: 574.1423\n",
      "Epoch 11/20\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 160.8714 - val_loss: 678.4905\n",
      "Epoch 12/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 155.5349 - val_loss: 507.2292\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "[8.19095667e+00 5.49399656e+00 8.81347307e-01 7.81564822e-01\n",
      " 3.51238057e-01 1.43235420e-01 4.09913921e-02 3.53324081e-02\n",
      " 2.44339253e-02 1.75337353e-02 1.33853528e-02 1.23424994e-02\n",
      " 6.63828566e-03 3.52672765e-03 3.10180225e-03 1.02230366e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -1.538312 -0.544704\n",
      "1 -0.930198 -0.333238\n",
      "2 -0.870208 -0.240347\n",
      "3 -0.788517 -0.178757\n",
      "4 -0.909442 -0.304579\n",
      "      comp1     comp2\n",
      "0 -0.623506 -2.289400\n",
      "1 -0.450795 -1.901779\n",
      "2 -0.334288 -2.275177\n",
      "3 -0.622983 -1.845581\n",
      "4 -0.643156 -1.711918\n",
      "(21320, 35, 2) (21320, 1) (100, 35, 2)\n",
      "Epoch 1/20\n",
      "667/667 [==============================] - 8s 9ms/step - loss: 878.0959 - val_loss: 921.2772\n",
      "Epoch 2/20\n",
      "667/667 [==============================] - 9s 13ms/step - loss: 314.5858 - val_loss: 690.3844\n",
      "Epoch 3/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 208.1879 - val_loss: 543.6920\n",
      "Epoch 4/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 193.8457 - val_loss: 583.5022\n",
      "Epoch 5/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 179.2947 - val_loss: 511.1933\n",
      "Epoch 6/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 179.4066 - val_loss: 668.8672\n",
      "Epoch 7/20\n",
      "667/667 [==============================] - 7s 11ms/step - loss: 172.8947 - val_loss: 481.0146\n",
      "Epoch 8/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 167.0548 - val_loss: 631.4310\n",
      "Epoch 9/20\n",
      "667/667 [==============================] - 7s 10ms/step - loss: 162.9904 - val_loss: 535.6326\n",
      "Epoch 10/20\n",
      "667/667 [==============================] - 6s 9ms/step - loss: 157.3337 - val_loss: 568.1228\n",
      "Epoch 11/20\n",
      "667/667 [==============================] - 6s 8ms/step - loss: 155.0340 - val_loss: 575.7477\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "CPU times: total: 15min 28s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_pca003 = pd.DataFrame()\n",
    "for SEED in range(5):  \n",
    "    tf.random.set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    # 0.20\t[64]\t0.3\ttanh\t32\t25\n",
    "    \n",
    "    # parameter's sample\n",
    "    # weights_file = \"weights_file_lstm_optimalmodel_all.h5\"\n",
    "    alpha = 0.1\n",
    "    sequence_length = 35\n",
    "    epochs = 20\n",
    "    nodes_per_layer = [64]\n",
    "    dropout = 0.2\n",
    "    activation = 'tanh'\n",
    "    batch_size = 32\n",
    "    remaining_sensors = remaining_sensors\n",
    "    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "    \n",
    "    #PCA data reduction \n",
    "    X_cr_train, X_cr_test= StandardScaler().fit_transform(X_train_interim[remaining_sensors]), StandardScaler().fit_transform(X_test_interim[remaining_sensors])\n",
    "    pca = PCA()\n",
    "    component_train , component_test = pca.fit(X_cr_train).transform(X_cr_train), pca.transform(X_cr_test)\n",
    "    # print(pca.explained_variance_, np_component) # choos component which lambda >1 # kaiser\n",
    "\n",
    "    np_component = len(pca.explained_variance_[pca.explained_variance_>1])\n",
    "    print(pca.explained_variance_,'\\n', \"Nb components: \", np_component) # choos component which lambda >1 # kaiser\n",
    "    comp = ['comp' + str(i) for i in range(1,np_component+1)]\n",
    "    X_train_interim[comp],  X_test_interim[comp]= component_train[:, :np_component], component_test[:, :np_component]\n",
    "    \n",
    "    # Rotate\n",
    "    rotator = Rotator(method='varimax')\n",
    "    X_train_interim[comp] = rotator.fit_transform(X_train_interim[comp])\n",
    "    X_test_interim[comp] = rotator.fit_transform(X_test_interim[comp])\n",
    "    print(X_train_interim[comp].head())\n",
    "    print(X_test_interim[comp].head())\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length, comp)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,comp, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    \n",
    "    input_shape = (sequence_length, len(comp))\n",
    "    model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "            \n",
    "    # Model fitting\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        start_time = time.time()\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        weights_file = model.get_weights()\n",
    "        model.set_weights(weights_file)  # reset optimizer and node weights before every training iteration\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size, 'TW' : sequence_length,\n",
    "         'time': training_time}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results_pca003 = pd.concat([results_pca003, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    results_pca003.to_csv('../results/pca/fd003_varimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>TW</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.961714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11933.343361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1117.577759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>50.961694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.260130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5653.835713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.407654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>86.691065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.916652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3737.031015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.431824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>63.303207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.380443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1912.213083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>507.229248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>76.991445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.932046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2638.054409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.747681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>75.760082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  std_RMSE       S_score  std_S_score          MSE  std_MSE nodes  \\\n",
       "0  27.961714       0.0  11933.343361          0.0  1117.577759      0.0  [64]   \n",
       "1  24.260130       0.0   5653.835713          0.0   791.407654      0.0  [64]   \n",
       "2  24.916652       0.0   3737.031015          0.0   701.431824      0.0  [64]   \n",
       "3  22.380443       0.0   1912.213083          0.0   507.229248      0.0  [64]   \n",
       "4  21.932046       0.0   2638.054409          0.0   575.747681      0.0  [64]   \n",
       "\n",
       "   dropout activation  batch_size  TW       time  \n",
       "0      0.2       tanh          32  35  50.961694  \n",
       "1      0.2       tanh          32  35  86.691065  \n",
       "2      0.2       tanh          32  35  63.303207  \n",
       "3      0.2       tanh          32  35  76.991445  \n",
       "4      0.2       tanh          32  35  75.760082  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pca003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 27) (13096, 26) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# Load data and preprocess\n",
    "train, test, y_test = prepare_data('FD001.txt')\n",
    "print(train.shape, test.shape, y_test.shape)\n",
    "sensor_names = ['T20','T24','T30','T50','P20','P15','P30','Nf','Nc','epr','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "remaining_sensors = ['T24','T30','T50', 'P15', 'P30','Nf','Nc','Ps30','phi',\n",
    "                    'NRf','NRc','BPR','htBleed','W31','W32']\n",
    "drop_sensors = [element for element in sensor_names if element not in remaining_sensors]\n",
    "\n",
    "rul_piecewise = 125\n",
    "train['RUL'].clip(upper=rul_piecewise, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16218316e+01 2.22745151e+00 7.53919107e-01 7.60689125e-02\n",
      " 5.80733626e-02 4.69453854e-02 4.15078334e-02 3.47383080e-02\n",
      " 3.32981565e-02 2.89969632e-02 2.53785317e-02 1.84836056e-02\n",
      " 1.69423744e-02 1.35008525e-02 3.59058504e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -3.350030 -0.498183\n",
      "1 -2.765970 -0.864560\n",
      "2 -2.981935 -0.884688\n",
      "3 -3.234127 -0.924249\n",
      "4 -3.089479 -0.789932\n",
      "      comp1     comp2\n",
      "0 -1.585337 -0.748141\n",
      "1 -2.355410  0.391989\n",
      "2 -1.888595  0.232093\n",
      "3 -2.040020  0.005877\n",
      "4 -2.349974 -0.057874\n",
      "(17731, 30, 2) (17731, 1) (100, 30, 2)\n",
      "Epoch 1/20\n",
      "278/278 [==============================] - 9s 27ms/step - loss: 1032.1738 - val_loss: 1147.0245\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - 5s 20ms/step - loss: 224.8445 - val_loss: 799.9646\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - 6s 22ms/step - loss: 192.9965 - val_loss: 536.2028\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - 6s 23ms/step - loss: 190.3034 - val_loss: 616.7360\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - 5s 18ms/step - loss: 177.5551 - val_loss: 639.8791\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - 5s 19ms/step - loss: 172.4712 - val_loss: 551.4032\n",
      "Epoch 7/20\n",
      "278/278 [==============================] - 7s 24ms/step - loss: 171.5444 - val_loss: 589.2596\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "[1.16218316e+01 2.22745151e+00 7.53919107e-01 7.60689125e-02\n",
      " 5.80733626e-02 4.69453854e-02 4.15078334e-02 3.47383080e-02\n",
      " 3.32981565e-02 2.89969632e-02 2.53785317e-02 1.84836056e-02\n",
      " 1.69423744e-02 1.35008525e-02 3.59058504e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -3.350030 -0.498183\n",
      "1 -2.765970 -0.864560\n",
      "2 -2.981935 -0.884688\n",
      "3 -3.234127 -0.924249\n",
      "4 -3.089479 -0.789932\n",
      "      comp1     comp2\n",
      "0 -1.585337 -0.748141\n",
      "1 -2.355410  0.391989\n",
      "2 -1.888595  0.232093\n",
      "3 -2.040020  0.005877\n",
      "4 -2.349974 -0.057874\n",
      "(17731, 30, 2) (17731, 1) (100, 30, 2)\n",
      "Epoch 1/20\n",
      "278/278 [==============================] - 9s 28ms/step - loss: 1188.7987 - val_loss: 894.2910\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - 10s 37ms/step - loss: 271.7660 - val_loss: 502.7173\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 205.9643 - val_loss: 457.4361\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 191.8845 - val_loss: 578.6658\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 184.6355 - val_loss: 479.0558\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - 4s 16ms/step - loss: 176.2958 - val_loss: 525.0728\n",
      "Epoch 7/20\n",
      "278/278 [==============================] - 6s 20ms/step - loss: 170.7124 - val_loss: 568.9773\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "[1.16218316e+01 2.22745151e+00 7.53919107e-01 7.60689125e-02\n",
      " 5.80733626e-02 4.69453854e-02 4.15078334e-02 3.47383080e-02\n",
      " 3.32981565e-02 2.89969632e-02 2.53785317e-02 1.84836056e-02\n",
      " 1.69423744e-02 1.35008525e-02 3.59058504e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -3.350030 -0.498183\n",
      "1 -2.765970 -0.864560\n",
      "2 -2.981935 -0.884688\n",
      "3 -3.234127 -0.924249\n",
      "4 -3.089479 -0.789932\n",
      "      comp1     comp2\n",
      "0 -1.585337 -0.748141\n",
      "1 -2.355410  0.391989\n",
      "2 -1.888595  0.232093\n",
      "3 -2.040020  0.005877\n",
      "4 -2.349974 -0.057874\n",
      "(17731, 30, 2) (17731, 1) (100, 30, 2)\n",
      "Epoch 1/20\n",
      "278/278 [==============================] - 9s 27ms/step - loss: 1044.3717 - val_loss: 822.8558\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - 13s 47ms/step - loss: 222.0361 - val_loss: 479.8091\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 197.9638 - val_loss: 577.5997\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - 8s 31ms/step - loss: 180.3703 - val_loss: 564.6158\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 172.7123 - val_loss: 663.9417\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 170.8524 - val_loss: 685.7092\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "[1.16218316e+01 2.22745151e+00 7.53919107e-01 7.60689125e-02\n",
      " 5.80733626e-02 4.69453854e-02 4.15078334e-02 3.47383080e-02\n",
      " 3.32981565e-02 2.89969632e-02 2.53785317e-02 1.84836056e-02\n",
      " 1.69423744e-02 1.35008525e-02 3.59058504e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -3.350030 -0.498183\n",
      "1 -2.765970 -0.864560\n",
      "2 -2.981935 -0.884688\n",
      "3 -3.234127 -0.924249\n",
      "4 -3.089479 -0.789932\n",
      "      comp1     comp2\n",
      "0 -1.585337 -0.748141\n",
      "1 -2.355410  0.391989\n",
      "2 -1.888595  0.232093\n",
      "3 -2.040020  0.005877\n",
      "4 -2.349974 -0.057874\n",
      "(17731, 30, 2) (17731, 1) (100, 30, 2)\n",
      "Epoch 1/20\n",
      "278/278 [==============================] - 14s 45ms/step - loss: 1034.0443 - val_loss: 914.7977\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - 9s 32ms/step - loss: 224.2757 - val_loss: 793.4895\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - 7s 24ms/step - loss: 197.8554 - val_loss: 783.1707\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - 9s 34ms/step - loss: 188.8551 - val_loss: 1020.0145\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - 8s 31ms/step - loss: 179.9243 - val_loss: 765.9411\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - 8s 30ms/step - loss: 173.7959 - val_loss: 651.3242\n",
      "Epoch 7/20\n",
      "278/278 [==============================] - 7s 27ms/step - loss: 167.3991 - val_loss: 743.1913\n",
      "Epoch 8/20\n",
      "278/278 [==============================] - 7s 25ms/step - loss: 167.4253 - val_loss: 889.8860\n",
      "Epoch 9/20\n",
      "278/278 [==============================] - 7s 24ms/step - loss: 162.3042 - val_loss: 792.0606\n",
      "Epoch 10/20\n",
      "278/278 [==============================] - 7s 24ms/step - loss: 158.7336 - val_loss: 642.1371\n",
      "Epoch 11/20\n",
      "278/278 [==============================] - 7s 23ms/step - loss: 157.9966 - val_loss: 688.3455\n",
      "Epoch 12/20\n",
      "278/278 [==============================] - 8s 28ms/step - loss: 151.8913 - val_loss: 665.2377\n",
      "Epoch 13/20\n",
      "278/278 [==============================] - 8s 29ms/step - loss: 147.1246 - val_loss: 691.1072\n",
      "Epoch 14/20\n",
      "278/278 [==============================] - 7s 26ms/step - loss: 146.5400 - val_loss: 740.7222\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "[1.16218316e+01 2.22745151e+00 7.53919107e-01 7.60689125e-02\n",
      " 5.80733626e-02 4.69453854e-02 4.15078334e-02 3.47383080e-02\n",
      " 3.32981565e-02 2.89969632e-02 2.53785317e-02 1.84836056e-02\n",
      " 1.69423744e-02 1.35008525e-02 3.59058504e-03] \n",
      " Nb components:  2\n",
      "      comp1     comp2\n",
      "0 -3.350030 -0.498183\n",
      "1 -2.765970 -0.864560\n",
      "2 -2.981935 -0.884688\n",
      "3 -3.234127 -0.924249\n",
      "4 -3.089479 -0.789932\n",
      "      comp1     comp2\n",
      "0 -1.585337 -0.748141\n",
      "1 -2.355410  0.391989\n",
      "2 -1.888595  0.232093\n",
      "3 -2.040020  0.005877\n",
      "4 -2.349974 -0.057874\n",
      "(17731, 30, 2) (17731, 1) (100, 30, 2)\n",
      "Epoch 1/20\n",
      "278/278 [==============================] - 9s 25ms/step - loss: 1102.9017 - val_loss: 673.4423\n",
      "Epoch 2/20\n",
      "278/278 [==============================] - 6s 22ms/step - loss: 228.3394 - val_loss: 1085.9513\n",
      "Epoch 3/20\n",
      "278/278 [==============================] - 6s 23ms/step - loss: 198.0927 - val_loss: 598.5001\n",
      "Epoch 4/20\n",
      "278/278 [==============================] - 6s 20ms/step - loss: 185.8109 - val_loss: 690.6564\n",
      "Epoch 5/20\n",
      "278/278 [==============================] - 6s 22ms/step - loss: 181.7178 - val_loss: 810.5400\n",
      "Epoch 6/20\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 176.5897 - val_loss: 734.5059\n",
      "Epoch 7/20\n",
      "278/278 [==============================] - 6s 21ms/step - loss: 167.1038 - val_loss: 671.2354\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "CPU times: total: 11min 26s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_pca001 = pd.DataFrame()\n",
    "for SEED in range(5):  \n",
    "    set_seed(SEED)\n",
    "    mse = []\n",
    "    R2_val = []\n",
    "    RMSE = []\n",
    "    score_val = []\n",
    "    \n",
    "    # 0.20\t[64]\t0.3\ttanh\t32\t25\n",
    "    \n",
    "    # parameter's sample\n",
    "    # weights_file = \"weights_file_lstm_optimalmodel_all.h5\"\n",
    "    alpha = 0.1\n",
    "    sequence_length = 30\n",
    "    epochs = 20\n",
    "    nodes_per_layer = [128]\n",
    "    dropout = 0.2\n",
    "    activation = 'tanh'\n",
    "    batch_size = 64\n",
    "    remaining_sensors = remaining_sensors    \n",
    "    # Data prepration\n",
    "    X_train_interim, X_test_interim = prep_data(train, test, drop_sensors, remaining_sensors, alpha)\n",
    "    \n",
    "    #PCA data reduction \n",
    "    X_cr_train, X_cr_test= StandardScaler().fit_transform(X_train_interim[remaining_sensors]), StandardScaler().fit_transform(X_test_interim[remaining_sensors])\n",
    "    pca = PCA()\n",
    "    component_train , component_test = pca.fit(X_cr_train).transform(X_cr_train), pca.transform(X_cr_test)\n",
    "    # print(pca.explained_variance_, np_component) # choos component which lambda >1 # kaiser\n",
    "\n",
    "    np_component = len(pca.explained_variance_[pca.explained_variance_>1])\n",
    "    print(pca.explained_variance_,'\\n', \"Nb components: \", np_component) # choos component which lambda >1 # kaiser\n",
    "    comp = ['comp' + str(i) for i in range(1,np_component+1)]\n",
    "    X_train_interim[comp],  X_test_interim[comp]= component_train[:, :np_component], component_test[:, :np_component]\n",
    "    \n",
    "    # Rotate\n",
    "    rotator = Rotator(method='varimax')\n",
    "    X_train_interim[comp] = rotator.fit_transform(X_train_interim[comp])\n",
    "    X_test_interim[comp] = rotator.fit_transform(X_test_interim[comp])\n",
    "    print(X_train_interim[comp].head())\n",
    "    print(X_test_interim[comp].head())\n",
    "\n",
    "    # create sequences train, test\n",
    "    train_array = gen_data_wrapper(X_train_interim, sequence_length, comp)\n",
    "    label_array = gen_label_wrapper(X_train_interim, sequence_length, ['RUL'])\n",
    "\n",
    "    test_gen = (list(gen_test_data(X_test_interim[X_test_interim['Unit']==unit_nr], sequence_length,comp, -99.))\n",
    "               for unit_nr in X_test_interim['Unit'].unique())\n",
    "    \n",
    "    test_array = np.concatenate(list(test_gen)).astype(np.float32)\n",
    "    test_rul = rul_piecewise_fct(y_test,rul_piecewise)\n",
    "    \n",
    "    input_shape = (sequence_length, len(comp))\n",
    "    model = model_lstm_1layer(input_shape, nodes_per_layer[0], dropout, activation)\n",
    "    print(train_array.shape, label_array.shape, test_array.shape)\n",
    "            \n",
    "    # Model fitting\n",
    "    cb = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        start_time = time.time()\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        weights_file = model.get_weights()\n",
    "        model.set_weights(weights_file)  # reset optimizer and node weights before every training iteration\n",
    "        history = model.fit(train_array, label_array,\n",
    "                                validation_data=(test_array, test_rul),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                callbacks=[cb],\n",
    "                                verbose=1)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        mse.append(history.history['val_loss'][-1])\n",
    "\n",
    "        y_hat_val_split = model.predict(test_array)\n",
    "        R2_val.append(r2_score(test_rul, y_hat_val_split))\n",
    "        RMSE.append(np.sqrt(mean_squared_error(test_rul, y_hat_val_split)))\n",
    "        score_val.append(compute_s_score(test_rul, y_hat_val_split))\n",
    "            \n",
    "        \n",
    "    #  append results\n",
    "    d = {'RMSE' :np.mean(RMSE), 'std_RMSE' :np.std(RMSE),\n",
    "         'S_score' :np.mean(score_val), 'std_S_score' :np.std(score_val),\n",
    "         'MSE':np.mean(mse), 'std_MSE':np.std(mse),\n",
    "         'nodes':str(nodes_per_layer), 'dropout':dropout, \n",
    "         'activation':activation, 'batch_size':batch_size, 'TW' : sequence_length,\n",
    "         'time': training_time}\n",
    "\n",
    "#     results = results.append(pd.DataFrame(d, index=[0]), ignore_index=True)\n",
    "    results_pca001 = pd.concat([results_pca001, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    results_pca001.to_csv('../results/pca/fd001_varimax.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>std_RMSE</th>\n",
       "      <th>S_score</th>\n",
       "      <th>std_S_score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>std_MSE</th>\n",
       "      <th>nodes</th>\n",
       "      <th>dropout</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>TW</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.156052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1257.228450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.259583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>44.204294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.387756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1317.097333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.977295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>50.187534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.904547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1207.393286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.709229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>55.045040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.340424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1613.314798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740.722168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>113.445598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.464262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1312.354064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>671.235413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>44.935172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  std_RMSE      S_score  std_S_score         MSE  std_MSE  nodes  \\\n",
       "0  23.156052       0.0  1257.228450          0.0  589.259583      0.0  [128]   \n",
       "1  21.387756       0.0  1317.097333          0.0  568.977295      0.0  [128]   \n",
       "2  21.904547       0.0  1207.393286          0.0  685.709229      0.0  [128]   \n",
       "3  25.340424       0.0  1613.314798          0.0  740.722168      0.0  [128]   \n",
       "4  24.464262       0.0  1312.354064          0.0  671.235413      0.0  [128]   \n",
       "\n",
       "   dropout activation  batch_size  TW        time  \n",
       "0      0.2       tanh          64  30   44.204294  \n",
       "1      0.2       tanh          64  30   50.187534  \n",
       "2      0.2       tanh          64  30   55.045040  \n",
       "3      0.2       tanh          64  30  113.445598  \n",
       "4      0.2       tanh          64  30   44.935172  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pca001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
